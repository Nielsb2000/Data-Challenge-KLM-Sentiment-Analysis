{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preprocessing (1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import sqlite3\n",
    "import re\n",
    "from datetime import datetime\n",
    "\n",
    "pd.set_option('display.max_colwidth', None)  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_runtime(start, stop):\n",
    "    \"\"\"\n",
    "    Calculates running time of every process. This cell is repeated in every notebook. \n",
    "    :param start: start time\n",
    "    :param stop: stop time\n",
    "    :return: output corresponding to running time for process \n",
    "    \"\"\"\n",
    "    \n",
    "    runtime = stop - start\n",
    "    \n",
    "    days, seconds = runtime.days, runtime.seconds\n",
    "    \n",
    "    hours = days * 24 + seconds // 3600\n",
    "    minutes = (seconds % 3600) // 60\n",
    "    seconds = (seconds % 60)\n",
    "    \n",
    "    return 'Runtime preprocessing {} records was: {} h, {} m {} s'.format(records, hours, minutes, seconds)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "start = datetime.now()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "conn_tweets = sqlite3.connect('tweets_airlines.db')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Cleaning tables by sorting on created columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "query_tweets = 'SELECT * FROM TWEETS'\n",
    "df_tweets = pd.read_sql_query(query_tweets, conn_tweets)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_tweets = df_tweets.sort_values(by='created_at')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "query_users = 'SELECT * FROM USERS'\n",
    "df_users = pd.read_sql_query(query_users, conn_tweets)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_users = df_users.sort_values(by='tweet_created_at')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "records = df_tweets.shape[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Removing duplicates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_tweets = df_tweets.drop_duplicates(subset=['tweet_id'])\n",
    "df_users = df_users.drop_duplicates(subset=['tweet_id'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Cleaning text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_text(text, mentioned_users): \n",
    "    \"\"\"\n",
    "    Tokenizes all text columns and only keeps part of the text that are useful. \n",
    "    :param text: string with text of the tweet\n",
    "    :param mentioned_users: users mentioned in the tweet \n",
    "    :return: string of tokenized text \n",
    "    \"\"\"\n",
    "    split = text.split()\n",
    "    \n",
    "    # Remove mentioned users at start of tweet\n",
    "\n",
    "    if split[0] == 'RT':\n",
    "        clean = [re.sub('@\\w+:', '', i) for i in split]\n",
    "        \n",
    "        m = (mentioned_users.count(\",\"))\n",
    "        \n",
    "        clean[:m+1] = [re.sub('@\\w+', '', i) for i in clean[:m+1]]\n",
    "    \n",
    "    elif split[0].startswith('@'):\n",
    "        m = (mentioned_users.count(\",\")) + 1\n",
    "        \n",
    "        clean = split\n",
    "        \n",
    "        clean[:m] = [re.sub('@\\w+', '', i) for i in clean[:m]]\n",
    "        \n",
    "    # Do not remove mentioned users when they don't appear at the start or after RT \n",
    "    \n",
    "    else: \n",
    "        clean = split\n",
    "        \n",
    "    # Remove all links \n",
    "        \n",
    "    tokenized_tweet = [re.sub('https:\\S+', '', i) for i in clean]\n",
    "    \n",
    "    return ' '.join(tokenized_tweet)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_tweets['tokenized_text'] = df_tweets.apply(lambda text: clean_text(text.full_text, text.mentioned_users), axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_users.to_sql('USERS', conn_tweets, if_exists=\"replace\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_tweets.to_sql('TWEETS', conn_tweets, if_exists=\"replace\", index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "conn_tweets.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "stop = datetime.now()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Runtime of Cleaning process for 753283 records was: 0 h, 1 m 4 s'"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "calculate_runtime(start, stop)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
